{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deepfashion2_tutorial.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1QFnG6i8nUitMD6cInG-CdM9-fVGsWwYL","authorship_tag":"ABX9TyPU11ZbbY8FfPU6QZwz3O0B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d08913ff4b1f4f8fab4f039fa4a58ab9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fe1eabea672e44cf8287e79bdbb94f86","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_69cc06a8018544e4a13bce7c88618aae","IPY_MODEL_80de53ccdabd49b0a1191c4f29fe2f11"]}},"fe1eabea672e44cf8287e79bdbb94f86":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69cc06a8018544e4a13bce7c88618aae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e997221b87fd4577aa515c3dd8bec64d","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":20000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":20000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4196bf63186b48fa853d5c9bf2b4f820"}},"80de53ccdabd49b0a1191c4f29fe2f11":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a64888d5302a4d4dbfb2e1f39a591e0c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 20000/20000 [2:16:55&lt;00:00,  2.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12b364fb2f164abb9a125728f62cb0eb"}},"e997221b87fd4577aa515c3dd8bec64d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4196bf63186b48fa853d5c9bf2b4f820":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a64888d5302a4d4dbfb2e1f39a591e0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"12b364fb2f164abb9a125728f62cb0eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aab746d36a8641aca18781edf90e1545":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_00de8a1706a7482caf8f2cd29a70824a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_bdcd1f43ca124498bfbcc533e9d9cd7a","IPY_MODEL_765cb6957c424349a3702bed03d02fff"]}},"00de8a1706a7482caf8f2cd29a70824a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bdcd1f43ca124498bfbcc533e9d9cd7a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_97a719ce890f41dba90b187be0626cc6","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":4000,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4000,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4d4745684bae401bbb654024a33fe91b"}},"765cb6957c424349a3702bed03d02fff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2107a8013f0f4eef9a3d3fed919770e6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4000/4000 [00:17&lt;00:00, 229.79it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f7c997f9db74275a8aa50286949e8ca"}},"97a719ce890f41dba90b187be0626cc6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4d4745684bae401bbb654024a33fe91b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2107a8013f0f4eef9a3d3fed919770e6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4f7c997f9db74275a8aa50286949e8ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"BJfoGLXrMYsd"},"source":["# Deepfashion2\n","It contains 13 popular clothing categories from both commercial shopping stores and consumers. \n","'short_sleeved_shirt', 'long_sleeved_shirt', 'short_sleeved_outwear', 'long_sleeved_outwear', 'vest', 'sling', 'shorts', 'trousers', 'skirt', 'short_sleeved_dress', 'long_sleeved_dress', 'vest_dress', 'sling_dress'\n","\n","사진 한 장당 Annotation 파일 하나가 있고, 이 annotation에는 item1(예를 들어 상의), item2(예를 들어 하의) 에 대한 설명이 있다. 이 안에는 item의 카테고리, segmentation 정보, landmark정보, keypoint정보 등이 들어 있다.\n","\n","![이미지](https://ifh.cc/g/Z2EPsx.jpg)"]},{"cell_type":"markdown","metadata":{"id":"DJ1F6dKPMb4D"},"source":["## Dataset Unzip\n","\n","Training images: train/image Training annotations: train/annos\n","\n","Validation images: validation/image Validation annotations: validation/annos\n","\n","Test images: test/image"]},{"cell_type":"code","metadata":{"id":"mohmJd7IDzqH"},"source":["!unzip /content/drive/MyDrive/Segmentation/test.zip -d /content/drive/MyDrive/Segmentation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ENBRUhHhFBQS"},"source":["!unzip /content/drive/MyDrive/Segmentation/train.zip -d /content/drive/MyDrive/Segmentation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8S0_nsPDZNMA"},"source":["!unzip /content/drive/MyDrive/Segmentation/validation.zip -d /content/drive/MyDrive/Segmentation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uyWA-iy3Y1Fj","executionInfo":{"status":"ok","timestamp":1626853405871,"user_tz":-540,"elapsed":5110,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"28a37e65-0eb5-4cf7-9ed0-9acc2848a98c"},"source":["from glob import glob\n","\n","train_data = glob('/content/drive/MyDrive/Segmentation/Deepfashion2_Training/dataset/train/image/*')\n","print(len(train_data))\n","json_data = glob('/content/drive/MyDrive/Segmentation/Deepfashion2_Training/dataset/train/annos/*')\n","print(len(json_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["191961\n","191961\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w3OQvHLQZ9PL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626851594026,"user_tz":-540,"elapsed":3479,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"0aaece73-0bbb-482a-d54f-23fbd194de89"},"source":["from glob import glob\n","\n","train_data = glob('/content/drive/MyDrive/Segmentation/Deepfashion2_Training/dataset/validation/image/*.jpg')\n","print(len(train_data))\n","json_data = glob('/content/drive/MyDrive/Segmentation/Deepfashion2_Training/dataset/validation/annos/*.json')\n","print(len(json_data))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32153\n","32153\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aVaAdqH7Mg5j"},"source":["## convert Dataset to coco format"]},{"cell_type":"code","metadata":{"id":"xwTJTCdFIg3b"},"source":["import json\n","from PIL import Image\n","import numpy as np\n","from tqdm.auto import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mj0dv0RKMndy"},"source":["dataset = {\n","    \"info\": {},\n","    \"licenses\": [],\n","    \"images\": [],\n","    \"annotations\": [],\n","    \"categories\": []\n","}\n","\n","dataset['categories'].append({\n","    'id': 1,\n","    'name': \"short_sleeved_shirt\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 2,\n","    'name': \"long_sleeved_shirt\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 3,\n","    'name': \"short_sleeved_outwear\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 4,\n","    'name': \"long_sleeved_outwear\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 5,\n","    'name': \"vest\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 6,\n","    'name': \"sling\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 7,\n","    'name': \"shorts\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 8,\n","    'name': \"trousers\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 9,\n","    'name': \"skirt\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 10,\n","    'name': \"short_sleeved_dress\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 11,\n","    'name': \"long_sleeved_dress\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 12,\n","    'name': \"vest_dress\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})\n","dataset['categories'].append({\n","    'id': 13,\n","    'name': \"sling_dress\",\n","    'supercategory': \"clothes\",\n","    'keypoints': ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294'],\n","    'skeleton': []\n","})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r9hQk9_ZMp9g"},"source":["num_images = 20000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["d08913ff4b1f4f8fab4f039fa4a58ab9","fe1eabea672e44cf8287e79bdbb94f86","69cc06a8018544e4a13bce7c88618aae","80de53ccdabd49b0a1191c4f29fe2f11","e997221b87fd4577aa515c3dd8bec64d","4196bf63186b48fa853d5c9bf2b4f820","a64888d5302a4d4dbfb2e1f39a591e0c","12b364fb2f164abb9a125728f62cb0eb"]},"id":"bV4JxcJeNN2u","executionInfo":{"status":"ok","timestamp":1626797774397,"user_tz":-540,"elapsed":6305312,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"dba13823-405b-420a-b8fb-a61681387d30"},"source":["sub_index = 0 # the index of ground truth instance\n","for num in tqdm(range(1, num_images+1)):\n","    json_name = '/content/drive/MyDrive/Segmentation/train/annos/' + str(num).zfill(6)+'.json'\n","    image_name = '/content/drive/MyDrive/Segmentation/train/image/' + str(num).zfill(6)+'.jpg'\n","\n","    if (num>=0):\n","        imag = Image.open(image_name)\n","        width, height = imag.size\n","        with open(json_name, 'r') as f:\n","            temp = json.loads(f.read())\n","            pair_id = temp['pair_id']\n","\n","            dataset['images'].append({\n","                'coco_url': '',\n","                'date_captured': '',\n","                'file_name': str(num).zfill(6) + '.jpg',\n","                'flickr_url': '',\n","                'id': num,\n","                'license': 0,\n","                'width': width,\n","                'height': height\n","            })\n","            for i in temp:\n","                if i == 'source' or i=='pair_id':\n","                    continue\n","                else:\n","                    points = np.zeros(294 * 3)\n","                    sub_index = sub_index + 1\n","                    box = temp[i]['bounding_box']\n","                    w = box[2]-box[0]\n","                    h = box[3]-box[1]\n","                    x_1 = box[0] # min x\n","                    y_1 = box[1] # min y\n","                    bbox=[x_1,y_1,w,h]\n","                    cat = temp[i]['category_id']\n","                    style = temp[i]['style']\n","                    seg = temp[i]['segmentation']\n","                    landmarks = temp[i]['landmarks']\n","\n","                    points_x = landmarks[0::3]\n","                    points_y = landmarks[1::3]\n","                    points_v = landmarks[2::3]\n","                    points_x = np.array(points_x)\n","                    points_y = np.array(points_y)\n","                    points_v = np.array(points_v)\n","\n","                    if cat == 1:\n","                        for n in range(0, 25):\n","                            points[3 * n] = points_x[n]\n","                            points[3 * n + 1] = points_y[n]\n","                            points[3 * n + 2] = points_v[n]\n","                    elif cat ==2:\n","                        for n in range(25, 58):\n","                            points[3 * n] = points_x[n - 25]\n","                            points[3 * n + 1] = points_y[n - 25]\n","                            points[3 * n + 2] = points_v[n - 25]\n","                    elif cat ==3:\n","                        for n in range(58, 89):\n","                            points[3 * n] = points_x[n - 58]\n","                            points[3 * n + 1] = points_y[n - 58]\n","                            points[3 * n + 2] = points_v[n - 58]\n","                    elif cat == 4:\n","                        for n in range(89, 128):\n","                            points[3 * n] = points_x[n - 89]\n","                            points[3 * n + 1] = points_y[n - 89]\n","                            points[3 * n + 2] = points_v[n - 89]\n","                    elif cat == 5:\n","                        for n in range(128, 143):\n","                            points[3 * n] = points_x[n - 128]\n","                            points[3 * n + 1] = points_y[n - 128]\n","                            points[3 * n + 2] = points_v[n - 128]\n","                    elif cat == 6:\n","                        for n in range(143, 158):\n","                            points[3 * n] = points_x[n - 143]\n","                            points[3 * n + 1] = points_y[n - 143]\n","                            points[3 * n + 2] = points_v[n - 143]\n","                    elif cat == 7:\n","                        for n in range(158, 168):\n","                            points[3 * n] = points_x[n - 158]\n","                            points[3 * n + 1] = points_y[n - 158]\n","                            points[3 * n + 2] = points_v[n - 158]\n","                    elif cat == 8:\n","                        for n in range(168, 182):\n","                            points[3 * n] = points_x[n - 168]\n","                            points[3 * n + 1] = points_y[n - 168]\n","                            points[3 * n + 2] = points_v[n - 168]\n","                    elif cat == 9:\n","                        for n in range(182, 190):\n","                            points[3 * n] = points_x[n - 182]\n","                            points[3 * n + 1] = points_y[n - 182]\n","                            points[3 * n + 2] = points_v[n - 182]\n","                    elif cat == 10:\n","                        for n in range(190, 219):\n","                            points[3 * n] = points_x[n - 190]\n","                            points[3 * n + 1] = points_y[n - 190]\n","                            points[3 * n + 2] = points_v[n - 190]\n","                    elif cat == 11:\n","                        for n in range(219, 256):\n","                            points[3 * n] = points_x[n - 219]\n","                            points[3 * n + 1] = points_y[n - 219]\n","                            points[3 * n + 2] = points_v[n - 219]\n","                    elif cat == 12:\n","                        for n in range(256, 275):\n","                            points[3 * n] = points_x[n - 256]\n","                            points[3 * n + 1] = points_y[n - 256]\n","                            points[3 * n + 2] = points_v[n - 256]\n","                    elif cat == 13:\n","                        for n in range(275, 294):\n","                            points[3 * n] = points_x[n - 275]\n","                            points[3 * n + 1] = points_y[n - 275]\n","                            points[3 * n + 2] = points_v[n - 275]\n","                    num_points = len(np.where(points_v > 0)[0])\n","\n","                    dataset['annotations'].append({\n","                        'area': w*h,\n","                        'bbox': bbox,\n","                        'category_id': cat,\n","                        'id': sub_index,\n","                        'pair_id': pair_id,\n","                        'image_id': num,\n","                        'iscrowd': 0,\n","                        'style': style,\n","                        'num_keypoints':num_points,\n","                        'keypoints':points.tolist(),\n","                        'segmentation': seg,\n","                    })"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d08913ff4b1f4f8fab4f039fa4a58ab9","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LViFRHv9PWHX"},"source":["json_name = '/content/drive/MyDrive/Segmentation/train/train.json'\n","with open(json_name, 'w') as f:\n","  json.dump(dataset, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aj5uxx7WtgD6"},"source":["num_images = 4000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["aab746d36a8641aca18781edf90e1545","00de8a1706a7482caf8f2cd29a70824a","bdcd1f43ca124498bfbcc533e9d9cd7a","765cb6957c424349a3702bed03d02fff","97a719ce890f41dba90b187be0626cc6","4d4745684bae401bbb654024a33fe91b","2107a8013f0f4eef9a3d3fed919770e6","4f7c997f9db74275a8aa50286949e8ca"]},"id":"ZTUlLO9nuyNM","executionInfo":{"status":"ok","timestamp":1626798316775,"user_tz":-540,"elapsed":17626,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"b9bb68b3-7b4d-4f1b-fb75-6fb1e171c92b"},"source":["sub_index = 0 # the index of ground truth instance\n","for num in tqdm(range(1, num_images+1)):\n","    json_name = '/content/drive/MyDrive/Segmentation/validation/annos/' + str(num).zfill(6)+'.json'\n","    image_name = '/content/drive/MyDrive/Segmentation/validation/image/' + str(num).zfill(6)+'.jpg'\n","\n","    if (num>=0):\n","        imag = Image.open(image_name)\n","        width, height = imag.size\n","        with open(json_name, 'r') as f:\n","            temp = json.loads(f.read())\n","            pair_id = temp['pair_id']\n","\n","            dataset['images'].append({\n","                'coco_url': '',\n","                'date_captured': '',\n","                'file_name': str(num).zfill(6) + '.jpg',\n","                'flickr_url': '',\n","                'id': num,\n","                'license': 0,\n","                'width': width,\n","                'height': height\n","            })\n","            for i in temp:\n","                if i == 'source' or i=='pair_id':\n","                    continue\n","                else:\n","                    points = np.zeros(294 * 3)\n","                    sub_index = sub_index + 1\n","                    box = temp[i]['bounding_box']\n","                    w = box[2]-box[0]\n","                    h = box[3]-box[1]\n","                    x_1 = box[0] # min x\n","                    y_1 = box[1] # min y\n","                    bbox=[x_1,y_1,w,h]\n","                    cat = temp[i]['category_id']\n","                    style = temp[i]['style']\n","                    seg = temp[i]['segmentation']\n","                    landmarks = temp[i]['landmarks']\n","\n","                    points_x = landmarks[0::3]\n","                    points_y = landmarks[1::3]\n","                    points_v = landmarks[2::3]\n","                    points_x = np.array(points_x)\n","                    points_y = np.array(points_y)\n","                    points_v = np.array(points_v)\n","\n","                    if cat == 1:\n","                        for n in range(0, 25):\n","                            points[3 * n] = points_x[n]\n","                            points[3 * n + 1] = points_y[n]\n","                            points[3 * n + 2] = points_v[n]\n","                    elif cat ==2:\n","                        for n in range(25, 58):\n","                            points[3 * n] = points_x[n - 25]\n","                            points[3 * n + 1] = points_y[n - 25]\n","                            points[3 * n + 2] = points_v[n - 25]\n","                    elif cat ==3:\n","                        for n in range(58, 89):\n","                            points[3 * n] = points_x[n - 58]\n","                            points[3 * n + 1] = points_y[n - 58]\n","                            points[3 * n + 2] = points_v[n - 58]\n","                    elif cat == 4:\n","                        for n in range(89, 128):\n","                            points[3 * n] = points_x[n - 89]\n","                            points[3 * n + 1] = points_y[n - 89]\n","                            points[3 * n + 2] = points_v[n - 89]\n","                    elif cat == 5:\n","                        for n in range(128, 143):\n","                            points[3 * n] = points_x[n - 128]\n","                            points[3 * n + 1] = points_y[n - 128]\n","                            points[3 * n + 2] = points_v[n - 128]\n","                    elif cat == 6:\n","                        for n in range(143, 158):\n","                            points[3 * n] = points_x[n - 143]\n","                            points[3 * n + 1] = points_y[n - 143]\n","                            points[3 * n + 2] = points_v[n - 143]\n","                    elif cat == 7:\n","                        for n in range(158, 168):\n","                            points[3 * n] = points_x[n - 158]\n","                            points[3 * n + 1] = points_y[n - 158]\n","                            points[3 * n + 2] = points_v[n - 158]\n","                    elif cat == 8:\n","                        for n in range(168, 182):\n","                            points[3 * n] = points_x[n - 168]\n","                            points[3 * n + 1] = points_y[n - 168]\n","                            points[3 * n + 2] = points_v[n - 168]\n","                    elif cat == 9:\n","                        for n in range(182, 190):\n","                            points[3 * n] = points_x[n - 182]\n","                            points[3 * n + 1] = points_y[n - 182]\n","                            points[3 * n + 2] = points_v[n - 182]\n","                    elif cat == 10:\n","                        for n in range(190, 219):\n","                            points[3 * n] = points_x[n - 190]\n","                            points[3 * n + 1] = points_y[n - 190]\n","                            points[3 * n + 2] = points_v[n - 190]\n","                    elif cat == 11:\n","                        for n in range(219, 256):\n","                            points[3 * n] = points_x[n - 219]\n","                            points[3 * n + 1] = points_y[n - 219]\n","                            points[3 * n + 2] = points_v[n - 219]\n","                    elif cat == 12:\n","                        for n in range(256, 275):\n","                            points[3 * n] = points_x[n - 256]\n","                            points[3 * n + 1] = points_y[n - 256]\n","                            points[3 * n + 2] = points_v[n - 256]\n","                    elif cat == 13:\n","                        for n in range(275, 294):\n","                            points[3 * n] = points_x[n - 275]\n","                            points[3 * n + 1] = points_y[n - 275]\n","                            points[3 * n + 2] = points_v[n - 275]\n","                    num_points = len(np.where(points_v > 0)[0])\n","\n","                    dataset['annotations'].append({\n","                        'area': w*h,\n","                        'bbox': bbox,\n","                        'category_id': cat,\n","                        'id': sub_index,\n","                        'pair_id': pair_id,\n","                        'image_id': num,\n","                        'iscrowd': 0,\n","                        'style': style,\n","                        'num_keypoints':num_points,\n","                        'keypoints':points.tolist(),\n","                        'segmentation': seg,\n","                    })"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"aab746d36a8641aca18781edf90e1545","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_CxyGIz3X7No"},"source":["# pip requirement.txt"]},{"cell_type":"code","metadata":{"id":"hDkaOeR7u8ty"},"source":["json_name = '/content/drive/MyDrive/Segmentation/validation/val.json'\n","with open(json_name, 'w') as f:\n","  json.dump(dataset, f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Kex_0ftvGCy","executionInfo":{"status":"ok","timestamp":1626798480827,"user_tz":-540,"elapsed":364,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"b07f20b2-9ed2-4f32-eccb-5c8f94e0cb46"},"source":["!cd /content/drive/MyDrive/Segmentation\n","!git clone https://github.com/Manishsinghrajput98/Deepfashion2_Training.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'Deepfashion2_Training' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"7gGhwbm9vmJE","executionInfo":{"status":"ok","timestamp":1626810089696,"user_tz":-540,"elapsed":52906,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"b555eea6-1e73-4d1f-9504-dfcf6a81cd6d"},"source":["!pip install -r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/requirement.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting absl-py==0.9.0\n","  Downloading absl-py-0.9.0.tar.gz (104 kB)\n","\u001b[?25l\r\u001b[K     |███▏                            | 10 kB 36.8 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20 kB 43.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 30 kB 44.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 61 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 92 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 102 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 104 kB 15.0 MB/s \n","\u001b[?25hRequirement already satisfied: astor==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 2)) (0.8.1)\n","Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 3)) (0.10.0)\n","Collecting Cython==0.29.14\n","  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 26.1 MB/s \n","\u001b[?25hCollecting decorator==4.4.1\n","  Downloading decorator-4.4.1-py2.py3-none-any.whl (9.2 kB)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Collecting google-pasta==0.1.8\n","  Downloading google_pasta-0.1.8-py3-none-any.whl (57 kB)\n","\u001b[K     |████████████████████████████████| 57 kB 6.3 MB/s \n","\u001b[?25hCollecting grpcio==1.26.0\n","  Downloading grpcio-1.26.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4 MB)\n","\u001b[K     |████████████████████████████████| 2.4 MB 66.8 MB/s \n","\u001b[?25hCollecting h5py==2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 62.8 MB/s \n","\u001b[?25hCollecting imageio==2.6.1\n","  Downloading imageio-2.6.1-py3-none-any.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 63.1 MB/s \n","\u001b[?25hCollecting Keras==2.2.4\n","  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n","\u001b[K     |████████████████████████████████| 312 kB 62.7 MB/s \n","\u001b[?25hCollecting Keras-Applications==1.0.8\n","  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 8.0 MB/s \n","\u001b[?25hCollecting Keras-Preprocessing==1.1.0\n","  Downloading Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41 kB)\n","\u001b[K     |████████████████████████████████| 41 kB 936 kB/s \n","\u001b[?25hCollecting kiwisolver==1.1.0\n","  Downloading kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 11.8 MB/s \n","\u001b[?25hCollecting Markdown==3.1.1\n","  Downloading Markdown-3.1.1-py2.py3-none-any.whl (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 9.0 MB/s \n","\u001b[?25hCollecting matplotlib==3.0.3\n","  Downloading matplotlib-3.0.3-cp37-cp37m-manylinux1_x86_64.whl (13.0 MB)\n","\u001b[K     |████████████████████████████████| 13.0 MB 57.5 MB/s \n","\u001b[?25hCollecting mock==3.0.5\n","  Downloading mock-3.0.5-py2.py3-none-any.whl (25 kB)\n","Collecting networkx==2.4\n","  Downloading networkx-2.4-py3-none-any.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 85.6 MB/s \n","\u001b[?25hCollecting numpy==1.18.1\n","  Downloading numpy-1.18.1-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s \n","\u001b[?25hCollecting Pillow==7.0.0\n","  Downloading Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 61.9 MB/s \n","\u001b[?25hCollecting protobuf==3.11.3\n","  Downloading protobuf-3.11.3-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 58.5 MB/s \n","\u001b[?25hCollecting pycocotools==2.0\n","  Downloading pycocotools-2.0.0.tar.gz (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 90.6 MB/s \n","\u001b[?25hCollecting pyparsing==2.4.6\n","  Downloading pyparsing-2.4.6-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 7.6 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 25)) (2.8.1)\n","Requirement already satisfied: PyWavelets==1.1.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 26)) (1.1.1)\n","Collecting PyYAML==5.3\n","  Downloading PyYAML-5.3.tar.gz (268 kB)\n","\u001b[K     |████████████████████████████████| 268 kB 80.4 MB/s \n","\u001b[?25hCollecting scikit-image==0.15.0\n","  Downloading scikit_image-0.15.0-cp37-cp37m-manylinux1_x86_64.whl (26.3 MB)\n","\u001b[K     |████████████████████████████████| 26.3 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 29)) (1.4.1)\n","Collecting six==1.14.0\n","  Downloading six-1.14.0-py2.py3-none-any.whl (10 kB)\n","Collecting tb-nightly==1.14.0a20190614\n","  Downloading tb_nightly-1.14.0a20190614-py3-none-any.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 58.9 MB/s \n","\u001b[?25hCollecting tensorboard==1.12.2\n","  Downloading tensorboard-1.12.2-py3-none-any.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 72.9 MB/s \n","\u001b[?25hCollecting tensorflow-estimator==1.14.0\n","  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n","\u001b[K     |████████████████████████████████| 488 kB 86.7 MB/s \n","\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 35)) (1.1.0)\n","Collecting tf-estimator-nightly==2.1.0.dev2020012309\n","  Downloading tf_estimator_nightly-2.1.0.dev2020012309-py2.py3-none-any.whl (453 kB)\n","\u001b[K     |████████████████████████████████| 453 kB 62.6 MB/s \n","\u001b[?25hCollecting Theano==1.0.4\n","  Downloading Theano-1.0.4.tar.gz (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 65.8 MB/s \n","\u001b[?25hCollecting Werkzeug==0.16.1\n","  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n","\u001b[K     |████████████████████████████████| 327 kB 69.2 MB/s \n","\u001b[?25hCollecting wrapt==1.11.2\n","  Downloading wrapt-1.11.2.tar.gz (27 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from kiwisolver==1.1.0->-r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 14)) (57.2.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tb-nightly==1.14.0a20190614->-r /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/requirement.txt (line 31)) (0.36.2)\n","Building wheels for collected packages: absl-py, pycocotools, PyYAML, Theano, wrapt\n","  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121940 sha256=238849d4c86a909646de3aedeeee12eb94392382b7d920f5fbc4961992a3dfd4\n","  Stored in directory: /root/.cache/pip/wheels/cc/af/1a/498a24d0730ef484019e007bb9e8cef3ac00311a672c049a3e\n","  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pycocotools: filename=pycocotools-2.0.0-cp37-cp37m-linux_x86_64.whl size=264015 sha256=107259607e3486f5e4a41b5dec97f198b4962572c6bf1788861501d89bc24fe8\n","  Stored in directory: /root/.cache/pip/wheels/4d/50/dc/e1f07e9eb5678a0ee21bc091220f1f3806ba8e48ef3f2083cb\n","  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyYAML: filename=PyYAML-5.3-cp37-cp37m-linux_x86_64.whl size=44244 sha256=f9a21a3402b8a8fb588c99a8c356f576261dd448c73cde6a59da9ab6bb2d249f\n","  Stored in directory: /root/.cache/pip/wheels/8a/55/a4/c0a81d27c33462cfdcb904db018f5550197e88b2b6b85beed2\n","  Building wheel for Theano (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Theano: filename=Theano-1.0.4-py3-none-any.whl size=2667192 sha256=c48f1740eee8bc1861b4541e1e11e21d77abd04bf96314edcc8cf4a4da1efaff\n","  Stored in directory: /root/.cache/pip/wheels/33/e0/86/12647586a15bd29c062c9996231380908fb2dcf6a5df1c6f84\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.11.2-cp37-cp37m-linux_x86_64.whl size=68502 sha256=3f1b7394f974137fc5500786fc8612b45d1538027f9b70a4994fdc6e8ffbeef3\n","  Stored in directory: /root/.cache/pip/wheels/23/5f/62/304b411f20be41821465a82bc98baabc5e68c3cdd1eb99db71\n","Successfully built absl-py pycocotools PyYAML Theano wrapt\n","Installing collected packages: six, numpy, pyparsing, Pillow, kiwisolver, h5py, decorator, Werkzeug, PyYAML, protobuf, networkx, matplotlib, Markdown, Keras-Preprocessing, Keras-Applications, imageio, grpcio, absl-py, wrapt, Theano, tf-estimator-nightly, tensorflow-estimator, tensorboard, tb-nightly, scikit-image, pycocotools, mock, Keras, google-pasta, gast, Cython\n","  Attempting uninstall: six\n","    Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 2.4.7\n","    Uninstalling pyparsing-2.4.7:\n","      Successfully uninstalled pyparsing-2.4.7\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 7.1.2\n","    Uninstalling Pillow-7.1.2:\n","      Successfully uninstalled Pillow-7.1.2\n","  Attempting uninstall: kiwisolver\n","    Found existing installation: kiwisolver 1.3.1\n","    Uninstalling kiwisolver-1.3.1:\n","      Successfully uninstalled kiwisolver-1.3.1\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: decorator\n","    Found existing installation: decorator 4.4.2\n","    Uninstalling decorator-4.4.2:\n","      Successfully uninstalled decorator-4.4.2\n","  Attempting uninstall: Werkzeug\n","    Found existing installation: Werkzeug 1.0.1\n","    Uninstalling Werkzeug-1.0.1:\n","      Successfully uninstalled Werkzeug-1.0.1\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: networkx\n","    Found existing installation: networkx 2.5.1\n","    Uninstalling networkx-2.5.1:\n","      Successfully uninstalled networkx-2.5.1\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","  Attempting uninstall: Markdown\n","    Found existing installation: Markdown 3.3.4\n","    Uninstalling Markdown-3.3.4:\n","      Successfully uninstalled Markdown-3.3.4\n","  Attempting uninstall: Keras-Preprocessing\n","    Found existing installation: Keras-Preprocessing 1.1.2\n","    Uninstalling Keras-Preprocessing-1.1.2:\n","      Successfully uninstalled Keras-Preprocessing-1.1.2\n","  Attempting uninstall: imageio\n","    Found existing installation: imageio 2.4.1\n","    Uninstalling imageio-2.4.1:\n","      Successfully uninstalled imageio-2.4.1\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.34.1\n","    Uninstalling grpcio-1.34.1:\n","      Successfully uninstalled grpcio-1.34.1\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 0.12.0\n","    Uninstalling absl-py-0.12.0:\n","      Successfully uninstalled absl-py-0.12.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.12.1\n","    Uninstalling wrapt-1.12.1:\n","      Successfully uninstalled wrapt-1.12.1\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.16.2\n","    Uninstalling scikit-image-0.16.2:\n","      Successfully uninstalled scikit-image-0.16.2\n","  Attempting uninstall: pycocotools\n","    Found existing installation: pycocotools 2.0.2\n","    Uninstalling pycocotools-2.0.2:\n","      Successfully uninstalled pycocotools-2.0.2\n","  Attempting uninstall: Keras\n","    Found existing installation: Keras 2.4.3\n","    Uninstalling Keras-2.4.3:\n","      Successfully uninstalled Keras-2.4.3\n","  Attempting uninstall: google-pasta\n","    Found existing installation: google-pasta 0.2.0\n","    Uninstalling google-pasta-0.2.0:\n","      Successfully uninstalled google-pasta-0.2.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Attempting uninstall: Cython\n","    Found existing installation: Cython 0.29.23\n","    Uninstalling Cython-0.29.23:\n","      Successfully uninstalled Cython-0.29.23\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.5.0 requires absl-py~=0.10, but you have absl-py 0.9.0 which is incompatible.\n","tensorflow 2.5.0 requires gast==0.4.0, but you have gast 0.3.3 which is incompatible.\n","tensorflow 2.5.0 requires google-pasta~=0.2, but you have google-pasta 0.1.8 which is incompatible.\n","tensorflow 2.5.0 requires grpcio~=1.34.0, but you have grpcio 1.26.0 which is incompatible.\n","tensorflow 2.5.0 requires h5py~=3.1.0, but you have h5py 2.10.0 which is incompatible.\n","tensorflow 2.5.0 requires keras-preprocessing~=1.1.2, but you have keras-preprocessing 1.1.0 which is incompatible.\n","tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.18.1 which is incompatible.\n","tensorflow 2.5.0 requires six~=1.15.0, but you have six 1.14.0 which is incompatible.\n","tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 1.12.2 which is incompatible.\n","tensorflow 2.5.0 requires tensorflow-estimator<2.6.0,>=2.5.0rc0, but you have tensorflow-estimator 1.14.0 which is incompatible.\n","tensorflow 2.5.0 requires wrapt~=1.12.1, but you have wrapt 1.11.2 which is incompatible.\n","tensorflow-metadata 1.1.0 requires protobuf<4,>=3.13, but you have protobuf 3.11.3 which is incompatible.\n","plotnine 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n","mizani 0.6.0 requires matplotlib>=3.1.1, but you have matplotlib 3.0.3 which is incompatible.\n","kapre 0.3.5 requires numpy>=1.18.5, but you have numpy 1.18.1 which is incompatible.\n","googleapis-common-protos 1.53.0 requires protobuf>=3.12.0, but you have protobuf 3.11.3 which is incompatible.\n","google-colab 1.0.0 requires six~=1.15.0, but you have six 1.14.0 which is incompatible.\n","google-api-core 1.26.3 requires protobuf>=3.12.0, but you have protobuf 3.11.3 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 7.0.0 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed Cython-0.29.14 Keras-2.2.4 Keras-Applications-1.0.8 Keras-Preprocessing-1.1.0 Markdown-3.1.1 Pillow-7.0.0 PyYAML-5.3 Theano-1.0.4 Werkzeug-0.16.1 absl-py-0.9.0 decorator-4.4.1 gast-0.3.3 google-pasta-0.1.8 grpcio-1.26.0 h5py-2.10.0 imageio-2.6.1 kiwisolver-1.1.0 matplotlib-3.0.3 mock-3.0.5 networkx-2.4 numpy-1.18.1 protobuf-3.11.3 pycocotools-2.0.0 pyparsing-2.4.6 scikit-image-0.15.0 six-1.14.0 tb-nightly-1.14.0a20190614 tensorboard-1.12.2 tensorflow-estimator-1.14.0 tf-estimator-nightly-2.1.0.dev2020012309 wrapt-1.11.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL","decorator","google","kiwisolver","matplotlib","mpl_toolkits","numpy","pyparsing","six"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R7om1_aC_7Gt","executionInfo":{"status":"ok","timestamp":1626810096760,"user_tz":-540,"elapsed":333,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"0361aaea-387a-475e-dc88-a48078ec5ef6"},"source":["%tensorflow_version 1.xt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.xt`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KzFQsXpjYB3l"},"source":["# train"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mS9OyIHwWzW","executionInfo":{"status":"ok","timestamp":1626809011657,"user_tz":-540,"elapsed":4633802,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"282ce186-80df-493f-a968-13fd618c2425"},"source":["%cd /content/drive/MyDrive/Segmentation/Deepfashion2_Training\n","!python main.py train --weights=coco"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training\n","WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n","Using TensorFlow backend.\n","Weights:  coco\n","Logs:  /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/logs\n","\n","Configurations:\n","BACKBONE                       resnet101\n","BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n","BATCH_SIZE                     4\n","BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n","COMPUTE_BACKBONE_SHAPE         None\n","DETECTION_MAX_INSTANCES        100\n","DETECTION_MIN_CONFIDENCE       0.7\n","DETECTION_NMS_THRESHOLD        0.3\n","FPN_CLASSIF_FC_LAYERS_SIZE     1024\n","GPU_COUNT                      2\n","GRADIENT_CLIP_NORM             5.0\n","IMAGES_PER_GPU                 2\n","IMAGE_CHANNEL_COUNT            3\n","IMAGE_MAX_DIM                  1024\n","IMAGE_META_SIZE                26\n","IMAGE_MIN_DIM                  800\n","IMAGE_MIN_SCALE                0\n","IMAGE_RESIZE_MODE              square\n","IMAGE_SHAPE                    [1024 1024    3]\n","LEARNING_MOMENTUM              0.9\n","LEARNING_RATE                  0.001\n","LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n","MASK_POOL_SIZE                 14\n","MASK_SHAPE                     [28, 28]\n","MAX_GT_INSTANCES               100\n","MEAN_PIXEL                     [123.7 116.8 103.9]\n","MINI_MASK_SHAPE                (56, 56)\n","NAME                           deepfashion2\n","NUM_CLASSES                    14\n","POOL_SIZE                      7\n","POST_NMS_ROIS_INFERENCE        1000\n","POST_NMS_ROIS_TRAINING         2000\n","PRE_NMS_LIMIT                  6000\n","ROI_POSITIVE_RATIO             0.33\n","RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n","RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n","RPN_ANCHOR_STRIDE              1\n","RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n","RPN_NMS_THRESHOLD              0.7\n","RPN_TRAIN_ANCHORS_PER_IMAGE    256\n","STEPS_PER_EPOCH                1000\n","TOP_DOWN_PYRAMID_SIZE          256\n","TRAIN_BN                       False\n","TRAIN_ROIS_PER_IMAGE           200\n","USE_MINI_MASK                  True\n","USE_RPN_ROIS                   True\n","VALIDATION_STEPS               50\n","WEIGHT_DECAY                   0.0001\n","train_img_dir                  /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/train/image\n","train_json_path                /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/train/train.json\n","valid_img_dir                  /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/validation/image\n","valid_json_path                /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/validation/val.json\n","\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py:552: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py:552: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py:599: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py:599: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/variables.py:2825: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","Loading weights  /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/mask_rcnn_coco.h5\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2021-07-20 18:06:32.307620: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2021-07-20 18:06:32.314425: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n","2021-07-20 18:06:32.314872: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557327ce3f80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 18:06:32.314908: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-20 18:06:32.317154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-20 18:06:32.543327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 18:06:32.544800: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557327ce4300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 18:06:32.544835: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2021-07-20 18:06:32.545172: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 18:06:32.546005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2021-07-20 18:06:32.562139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2021-07-20 18:06:32.747501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2021-07-20 18:06:32.831983: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2021-07-20 18:06:32.855556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2021-07-20 18:06:33.065735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2021-07-20 18:06:33.188060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2021-07-20 18:06:33.193690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 18:06:33.193862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 18:06:33.194814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 18:06:33.195675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2021-07-20 18:06:33.195780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2021-07-20 18:06:33.197704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 18:06:33.197754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2021-07-20 18:06:33.197783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2021-07-20 18:06:33.197975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 18:06:33.198890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 18:06:33.199806: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-20 18:06:33.199868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15224 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","2021-07-20 18:06:34.019727: W tensorflow/core/common_runtime/colocation_graph.cc:983] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n","  /job:localhost/replica:0/task:0/device:GPU:0\n","  /job:localhost/replica:0/task:0/device:CPU:0].\n","See below for details of this colocation group:\n","Colocation Debug Info:\n","Colocation group had the following types and supported devices: \n","Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:1' assigned_device_name_='' resource_device_name_='/device:GPU:1' supported_device_types_=[GPU, CPU] possible_devices_=[]\n","IsVariableInitialized: GPU CPU \n","Identity: GPU CPU XLA_CPU XLA_GPU \n","VariableV2: GPU CPU \n","Assign: GPU CPU \n","\n","Colocation members, user-requested devices, and framework assigned devices, if any:\n","  tower_1/mask_rcnn/anchors/Variable (VariableV2) /device:GPU:1\n","  tower_1/mask_rcnn/anchors/Variable/Assign (Assign) /device:GPU:1\n","  tower_1/mask_rcnn/anchors/Variable/read (Identity) /device:GPU:1\n","  IsVariableInitialized_694 (IsVariableInitialized) /device:GPU:1\n","\n","2021-07-20 18:06:34.020086: W tensorflow/core/common_runtime/colocation_graph.cc:983] Failed to place the graph without changing the devices of some resources. Some of the operations (that had to be colocated with resource generating operations) are not supported on the resources' devices. Current candidate devices are [\n","  /job:localhost/replica:0/task:0/device:GPU:0\n","  /job:localhost/replica:0/task:0/device:CPU:0].\n","See below for details of this colocation group:\n","Colocation Debug Info:\n","Colocation group had the following types and supported devices: \n","Root Member(assigned_device_name_index_=-1 requested_device_name_='/device:GPU:1' assigned_device_name_='' resource_device_name_='/device:GPU:1' supported_device_types_=[GPU, CPU] possible_devices_=[]\n","IsVariableInitialized: GPU CPU \n","Identity: GPU CPU XLA_CPU XLA_GPU \n","VariableV2: GPU CPU \n","Assign: GPU CPU \n","\n","Colocation members, user-requested devices, and framework assigned devices, if any:\n","  tower_1/mask_rcnn/Variable (VariableV2) /device:GPU:1\n","  tower_1/mask_rcnn/Variable/Assign (Assign) /device:GPU:1\n","  tower_1/mask_rcnn/Variable/read (Identity) /device:GPU:1\n","  IsVariableInitialized_695 (IsVariableInitialized) /device:GPU:1\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","loading annotations into memory...\n","Done (t=5.65s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=8.23s)\n","creating index...\n","index created!\n","\n","Starting at epoch 0. LR=0.001\n","\n","Checkpoint Path: /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/logs/deepfashion220210720T1806/mask_rcnn_deepfashion2_{epoch:04d}.h5\n","Selecting layers to train\n","fpn_c5p5               (Conv2D)\n","fpn_c4p4               (Conv2D)\n","fpn_c3p3               (Conv2D)\n","fpn_c2p2               (Conv2D)\n","fpn_p5                 (Conv2D)\n","fpn_p2                 (Conv2D)\n","fpn_p3                 (Conv2D)\n","fpn_p4                 (Conv2D)\n","In model:  rpn_model\n","    rpn_conv_shared        (Conv2D)\n","    rpn_class_raw          (Conv2D)\n","    rpn_bbox_pred          (Conv2D)\n","mrcnn_mask_conv1       (TimeDistributed)\n","mrcnn_mask_bn1         (TimeDistributed)\n","mrcnn_mask_conv2       (TimeDistributed)\n","mrcnn_mask_bn2         (TimeDistributed)\n","mrcnn_class_conv1      (TimeDistributed)\n","mrcnn_class_bn1        (TimeDistributed)\n","mrcnn_mask_conv3       (TimeDistributed)\n","mrcnn_mask_bn3         (TimeDistributed)\n","mrcnn_class_conv2      (TimeDistributed)\n","mrcnn_class_bn2        (TimeDistributed)\n","mrcnn_mask_conv4       (TimeDistributed)\n","mrcnn_mask_bn4         (TimeDistributed)\n","mrcnn_bbox_fc          (TimeDistributed)\n","mrcnn_mask_deconv      (TimeDistributed)\n","mrcnn_class_logits     (TimeDistributed)\n","mrcnn_mask             (TimeDistributed)\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n","  UserWarning('Using a generator with `use_multiprocessing=True`'\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n","\n","Epoch 1/30\n","2021-07-20 18:08:01.408658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2021-07-20 18:08:02.696240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 18:08:17.828882: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n","1000/1000 [==============================] - 1151s 1s/step - loss: 1.3782 - rpn_class_loss: 0.0089 - rpn_bbox_loss: 0.3816 - mrcnn_class_loss: 0.3095 - mrcnn_bbox_loss: 0.3337 - mrcnn_mask_loss: 0.3446 - val_loss: 5.3039 - val_rpn_class_loss: 0.1239 - val_rpn_bbox_loss: 2.6209 - val_mrcnn_class_loss: 0.3350 - val_mrcnn_bbox_loss: 0.8117 - val_mrcnn_mask_loss: 1.4123\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","Epoch 2/30\n","1000/1000 [==============================] - 1065s 1s/step - loss: 1.0101 - rpn_class_loss: 0.0057 - rpn_bbox_loss: 0.3064 - mrcnn_class_loss: 0.2454 - mrcnn_bbox_loss: 0.2087 - mrcnn_mask_loss: 0.2439 - val_loss: 6.7721 - val_rpn_class_loss: 0.1508 - val_rpn_bbox_loss: 3.7538 - val_mrcnn_class_loss: 0.3388 - val_mrcnn_bbox_loss: 0.8083 - val_mrcnn_mask_loss: 1.7204\n","Epoch 3/30\n","1000/1000 [==============================] - 1062s 1s/step - loss: 0.9937 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.3070 - mrcnn_class_loss: 0.2488 - mrcnn_bbox_loss: 0.1932 - mrcnn_mask_loss: 0.2387 - val_loss: 5.8007 - val_rpn_class_loss: 0.1327 - val_rpn_bbox_loss: 3.1696 - val_mrcnn_class_loss: 0.4045 - val_mrcnn_bbox_loss: 0.7766 - val_mrcnn_mask_loss: 1.3174\n","Epoch 4/30\n"," 999/1000 [============================>.] - ETA: 1s - loss: 0.9203 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.2895 - mrcnn_class_loss: 0.2361 - mrcnn_bbox_loss: 0.1668 - mrcnn_mask_loss: 0.2220ERROR:root:Error processing image {'id': 3352, 'source': 'deepfashion2', 'path': '/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/validation/image/003352.jpg', 'width': 468, 'height': 389, 'annotations': [{'area': 162526, 'bbox': [85, 89, 329, 494], 'category_id': 1, 'id': 5461, 'pair_id': 823, 'image_id': 3877, 'iscrowd': 0, 'style': 7, 'num_keypoints': 25, 'keypoints': [276.0, 260.0, 1.0, 251.0, 200.0, 1.0, 217.0, 251.0, 2.0, 210.0, 294.0, 2.0, 278.0, 308.0, 2.0, 350.0, 279.0, 2.0, 235.0, 152.0, 1.0, 209.0, 125.0, 2.0, 191.0, 97.0, 2.0, 144.0, 159.0, 2.0, 169.0, 185.0, 2.0, 180.0, 211.0, 2.0, 161.0, 240.0, 2.0, 126.0, 298.0, 2.0, 97.0, 355.0, 2.0, 100.0, 506.0, 2.0, 242.0, 557.0, 2.0, 267.0, 484.0, 2.0, 304.0, 424.0, 2.0, 315.0, 407.0, 2.0, 319.0, 441.0, 2.0, 316.0, 477.0, 2.0, 404.0, 466.0, 2.0, 401.0, 387.0, 2.0, 380.0, 316.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[250.78842866535504, 200.31148680379744, 230.0813186813187, 224.00879120879122, 217.26153846153846, 244.25054945054944, 215.23736263736265, 261.7934065934066, 209.83956043956044, 289.45714285714286, 209.16483516483515, 301.6021978021978, 219.28571428571428, 309.6989010989011, 253.6967032967033, 315.0967032967033, 270.5648351648352, 307.6747252747253, 305.6505494505495, 294.1802197802198, 327.91648351648354, 285.40879120879123, 343.4351648351648, 279.33626373626373, 349.5076923076923, 277.9868131868132, 350.1824175824176, 268.5406593406593, 345.4593406593407, 258.4197802197802, 336.6879120879121, 248.2989010989011, 332.63956043956046, 239.52747252747253, 340.73626373626377, 240.20219780219782, 353.55604395604394, 255.04615384615386, 354.9054945054945, 265.167032967033, 352.8813186813187, 279.33626373626373, 354.1642904104438, 283.93188691650266, 358.63503334272536, 290.5065088757402, 359.42398797783386, 294.4512820512828, 367.83950408565795, 298.1330703484558, 369.417413355875, 308.3894806048665, 377.3069597069601, 311.0193293885615, 381.25173288250267, 315.75305719921255, 383.09262703108914, 329.42827087442674, 390.45620362543525, 339.68468113083736, 393.6120221658693, 347.5742274819225, 397.81978021978136, 351.519000657465, 398.5474030243256, 361.5623931623929, 400.91426692965115, 380.4973044049971, 402.4921761998682, 393.6465483234723, 402.4921761998682, 400.4841551610794, 406.96291913214975, 409.162656147273, 405.3850098619327, 414.68533859303255, 401.1772518080207, 418.63011176857515, 403.2811308349767, 434.93517422748437, 402.7551610782377, 449.399342537807, 405.64799474030224, 468.07126890204177, 399.33635765943416, 458.34082840237016, 388.0280078895455, 451.50322156476307, 377.7715976331349, 448.347403024329, 357.2587771203136, 446.5065088757425, 342.5316239316214, 447.55844838922053, 325.43760683760365, 452.5551610782411, 319.9149243918441, 460.4447074293262, 316.49612097304055, 468.07126890204177, 317.76365173288195, 480.7577345731194, 309.34813562505786, 471.0272940734478, 314.6078331924479, 460.7708838170372, 314.87081807081745, 444.20283647975845, 316.18574246266496, 437.36522964215135, 312.76693904386144, 433.15747158823933, 313.8188785573394, 429.4756832910663, 315.39678782755647, 427.63478914247975, 313.8188785573394, 417.37837888606913, 312.5039541654919, 419.21927303465566, 310.6630600169054, 422.6380764534592, 303.2994834225593, 423.4270310885677, 301.4585892739728, 431.05359256128327, 297.77680097679973, 438.1541842772599, 289.0982999906061, 437.89119939889036, 285.6794965718026, 446.043730628345, 283.83860242321606, 456.3001408847556, 275.4230863153919, 457.08909551986414, 269.9004038696323, 467.60849065464424, 269.63741899126285, 488.384296045835, 271.2153282614799, 498.1147365455067, 260.69593312669974, 506.79323753170024, 253.0910303371841, 518.3058138442748, 251.25013618859757, 525.9323753169904, 249.14625716164153, 531.7180426411195, 248.88327228327202, 543.8153470461167, 242.57163520240394, 558.2795153564393, 231.2632854325153, 569.3248802479585, 209.83956043956044, 574.8659340659341, 187.32129238283102, 572.3954916877994, 154.1851977082736, 555.8274443505208, 123.9419366957807, 531.369850662157, 110.94730910115635, 521.4168122475834, 95.43120127735565, 494.59235465389406, 90.6974734667046, 480.39117122194085, 89.38254907485707, 453.56671362825153, 98.06105006105068, 430.1610594533657, 104.37268714191876, 388.6094486709842, 107.2655208039833, 373.88229548229197, 101.18491593876232, 367.68009768009756, 95.92521837137225, 360.31652108575145, 96.45118812811126, 352.4269747346663, 117.22699351930203, 316.9240161547834, 124.06460035690912, 304.8267117497862, 125.90549450549564, 294.8332863717451, 136.6878745186453, 271.6906170752288, 158.74372123602885, 238.62171503710016, 170.0520710059175, 225.7354559969945, 176.8896778435246, 216.53098525406187, 179.2565417488501, 210.2193481731938, 173.20788954635154, 193.12533107917608, 166.37028270874444, 182.34295106602644, 158.74372123602885, 173.1384803230938, 152.43208415516077, 163.9340095801612, 143.22761341222815, 158.41132713440163, 147.1723865877707, 143.15820418897044, 164.26640368178843, 120.10109890109891, 179.2565417488501, 104.8479759556677, 189.77593688363027, 95.64350521273509, 196.35055884286783, 103.27006668545069, 203.71413543721394, 112.47453742838331, 210.02577251808202, 121.41602329294642, 211.86666666666855, 127.2016906170755, 221.8600920447097, 133.2503428195741, 235.00933596318484, 151.1333145487003]]}, {'area': 74327, 'bbox': [130, 371, 233, 319], 'category_id': 9, 'id': 5462, 'pair_id': 823, 'image_id': 3878, 'iscrowd': 0, 'style': 8, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 389.0, 2.0, 201.0, 401.0, 1.0, 263.0, 404.0, 1.0, 165.0, 499.0, 2.0, 190.0, 591.0, 2.0, 272.0, 636.0, 2.0, 358.0, 670.0, 2.0, 325.0, 514.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[151.83262890955086, 389.4188503803873, 172.09890109890253, 401.10524091293314, 200.79712595097718, 401.253169907016, 225.62967032967032, 402.854691462382, 247.52316145393345, 401.3754015215534, 263.2036348267165, 404.48191039729346, 276.93795435333567, 433.56897717666624, 291.5829247675387, 452.65181741335505, 306.8196111580732, 475.8766694843639, 320.44412510566326, 500.2672020287382, 329.6157227388005, 513.1370245139469, 334.64530853761767, 522.6044801352499, 335.82874049028055, 534.2908706677957, 335.46289095519745, 543.1231614539245, 340.3445477599318, 558.0639898562932, 343.4510566356718, 578.9219780219763, 346.8534234995776, 605.5491969568909, 354.15950972104685, 639.9953508030401, 357.70980557903545, 663.0722738799661, 359.7808114961955, 670.1728655959433, 355.19501267962687, 678.1610312764177, 349.7216398985611, 681.7113271344064, 342.9169061707496, 679.3444632290806, 338.92282333051236, 673.1314454776006, 331.27218934911684, 674.9012679628056, 324.17159763313964, 673.2740490278941, 319.7337278106539, 661.2918005071825, 318.69822485207385, 649.1616229923881, 314.5562130177538, 634.516652578185, 307.5220625528345, 617.0752324598457, 299.82975486052584, 616.3355874894314, 290.36229923922286, 620.3296703296686, 280.74691462383703, 630.9805579036345, 272.6108199492798, 640.5959425190202, 264.4747252747226, 649.0278951817432, 253.83981403212442, 648.684192730346, 244.66821639898717, 643.5066779374459, 235.79247675401564, 639.6605240912916, 229.53693998309336, 621.1357565511408, 218.8860524091275, 588.7393068469947, 206.36880811496465, 598.2360101437025, 195.56999154691596, 598.9756551141169, 188.46939983093873, 591.431276415891, 181.9879966187681, 564.7739644970425, 173.85190194421088, 542.4366863905307, 169.48402366864252, 529.1443786982304, 160.75621301775385, 487.72426035502986, 154.24733727810806, 465.2390532544353, 151.14082840236802, 443.6414201183379, 144.67802197802393, 412.19103972949887]]}, {'area': 52074, 'bbox': [91, 29, 263, 198], 'category_id': 9, 'id': 4703, 'pair_id': 714, 'image_id': 3352, 'iscrowd': 0, 'style': 2, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 157.0, 31.0, 1.0, 228.0, 45.0, 1.0, 302.0, 33.0, 1.0, 123.0, 111.0, 2.0, 96.0, 203.0, 2.0, 241.0, 221.0, 2.0, 352.0, 205.0, 2.0, 329.0, 125.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[156.60540927216823, 31.735591001796195, 191.3027397260274, 41.03150684931507, 226.9879120879121, 44.45714285714286, 270.7013698630137, 40.49863013698631, 302.05716416548546, 32.822793826670235, 312.4176006818677, 72.94424827250536, 319.89682505860014, 93.99687985145583, 329.5921159173273, 124.19078566863479, 339.1840187513315, 153.88316641806878, 353.0344342637989, 204.85269550394887, 341.954101853825, 205.40671212444755, 331.98180268484845, 213.99396974217737, 316.95544732276005, 217.92225198624212, 306.7061398435342, 217.3682353657434, 288.9776079875759, 220.41532677848625, 269.5870262701215, 222.90840157073038, 242.60300143070478, 224.60440473653824, 245.37308453319827, 220.44928008279803, 230.1376274694841, 222.1113299442941, 210.7408663358824, 224.3513165504859, 182.7800036528541, 217.70311710450156, 182.7800036528541, 217.70311710450156, 97.46373626373627, 203.04945054945057, 109.79562265988966, 153.58841739976975, 121.87751057806436, 111.6011932665678, 134.02806916075644, 82.3378466408924, 149.54053453471994, 56.85308209795235]]}]}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1702, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1258, in load_image_gt\n","    class_ids = class_ids[_idx]\n","IndexError: boolean index did not match indexed array along dimension 0; dimension is 3 but corresponding boolean dimension is 2\n","ERROR:root:Error processing image {'id': 3352, 'source': 'deepfashion2', 'path': '/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/validation/image/003352.jpg', 'width': 468, 'height': 389, 'annotations': [{'area': 162526, 'bbox': [85, 89, 329, 494], 'category_id': 1, 'id': 5461, 'pair_id': 823, 'image_id': 3877, 'iscrowd': 0, 'style': 7, 'num_keypoints': 25, 'keypoints': [276.0, 260.0, 1.0, 251.0, 200.0, 1.0, 217.0, 251.0, 2.0, 210.0, 294.0, 2.0, 278.0, 308.0, 2.0, 350.0, 279.0, 2.0, 235.0, 152.0, 1.0, 209.0, 125.0, 2.0, 191.0, 97.0, 2.0, 144.0, 159.0, 2.0, 169.0, 185.0, 2.0, 180.0, 211.0, 2.0, 161.0, 240.0, 2.0, 126.0, 298.0, 2.0, 97.0, 355.0, 2.0, 100.0, 506.0, 2.0, 242.0, 557.0, 2.0, 267.0, 484.0, 2.0, 304.0, 424.0, 2.0, 315.0, 407.0, 2.0, 319.0, 441.0, 2.0, 316.0, 477.0, 2.0, 404.0, 466.0, 2.0, 401.0, 387.0, 2.0, 380.0, 316.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[250.78842866535504, 200.31148680379744, 230.0813186813187, 224.00879120879122, 217.26153846153846, 244.25054945054944, 215.23736263736265, 261.7934065934066, 209.83956043956044, 289.45714285714286, 209.16483516483515, 301.6021978021978, 219.28571428571428, 309.6989010989011, 253.6967032967033, 315.0967032967033, 270.5648351648352, 307.6747252747253, 305.6505494505495, 294.1802197802198, 327.91648351648354, 285.40879120879123, 343.4351648351648, 279.33626373626373, 349.5076923076923, 277.9868131868132, 350.1824175824176, 268.5406593406593, 345.4593406593407, 258.4197802197802, 336.6879120879121, 248.2989010989011, 332.63956043956046, 239.52747252747253, 340.73626373626377, 240.20219780219782, 353.55604395604394, 255.04615384615386, 354.9054945054945, 265.167032967033, 352.8813186813187, 279.33626373626373, 354.1642904104438, 283.93188691650266, 358.63503334272536, 290.5065088757402, 359.42398797783386, 294.4512820512828, 367.83950408565795, 298.1330703484558, 369.417413355875, 308.3894806048665, 377.3069597069601, 311.0193293885615, 381.25173288250267, 315.75305719921255, 383.09262703108914, 329.42827087442674, 390.45620362543525, 339.68468113083736, 393.6120221658693, 347.5742274819225, 397.81978021978136, 351.519000657465, 398.5474030243256, 361.5623931623929, 400.91426692965115, 380.4973044049971, 402.4921761998682, 393.6465483234723, 402.4921761998682, 400.4841551610794, 406.96291913214975, 409.162656147273, 405.3850098619327, 414.68533859303255, 401.1772518080207, 418.63011176857515, 403.2811308349767, 434.93517422748437, 402.7551610782377, 449.399342537807, 405.64799474030224, 468.07126890204177, 399.33635765943416, 458.34082840237016, 388.0280078895455, 451.50322156476307, 377.7715976331349, 448.347403024329, 357.2587771203136, 446.5065088757425, 342.5316239316214, 447.55844838922053, 325.43760683760365, 452.5551610782411, 319.9149243918441, 460.4447074293262, 316.49612097304055, 468.07126890204177, 317.76365173288195, 480.7577345731194, 309.34813562505786, 471.0272940734478, 314.6078331924479, 460.7708838170372, 314.87081807081745, 444.20283647975845, 316.18574246266496, 437.36522964215135, 312.76693904386144, 433.15747158823933, 313.8188785573394, 429.4756832910663, 315.39678782755647, 427.63478914247975, 313.8188785573394, 417.37837888606913, 312.5039541654919, 419.21927303465566, 310.6630600169054, 422.6380764534592, 303.2994834225593, 423.4270310885677, 301.4585892739728, 431.05359256128327, 297.77680097679973, 438.1541842772599, 289.0982999906061, 437.89119939889036, 285.6794965718026, 446.043730628345, 283.83860242321606, 456.3001408847556, 275.4230863153919, 457.08909551986414, 269.9004038696323, 467.60849065464424, 269.63741899126285, 488.384296045835, 271.2153282614799, 498.1147365455067, 260.69593312669974, 506.79323753170024, 253.0910303371841, 518.3058138442748, 251.25013618859757, 525.9323753169904, 249.14625716164153, 531.7180426411195, 248.88327228327202, 543.8153470461167, 242.57163520240394, 558.2795153564393, 231.2632854325153, 569.3248802479585, 209.83956043956044, 574.8659340659341, 187.32129238283102, 572.3954916877994, 154.1851977082736, 555.8274443505208, 123.9419366957807, 531.369850662157, 110.94730910115635, 521.4168122475834, 95.43120127735565, 494.59235465389406, 90.6974734667046, 480.39117122194085, 89.38254907485707, 453.56671362825153, 98.06105006105068, 430.1610594533657, 104.37268714191876, 388.6094486709842, 107.2655208039833, 373.88229548229197, 101.18491593876232, 367.68009768009756, 95.92521837137225, 360.31652108575145, 96.45118812811126, 352.4269747346663, 117.22699351930203, 316.9240161547834, 124.06460035690912, 304.8267117497862, 125.90549450549564, 294.8332863717451, 136.6878745186453, 271.6906170752288, 158.74372123602885, 238.62171503710016, 170.0520710059175, 225.7354559969945, 176.8896778435246, 216.53098525406187, 179.2565417488501, 210.2193481731938, 173.20788954635154, 193.12533107917608, 166.37028270874444, 182.34295106602644, 158.74372123602885, 173.1384803230938, 152.43208415516077, 163.9340095801612, 143.22761341222815, 158.41132713440163, 147.1723865877707, 143.15820418897044, 164.26640368178843, 120.10109890109891, 179.2565417488501, 104.8479759556677, 189.77593688363027, 95.64350521273509, 196.35055884286783, 103.27006668545069, 203.71413543721394, 112.47453742838331, 210.02577251808202, 121.41602329294642, 211.86666666666855, 127.2016906170755, 221.8600920447097, 133.2503428195741, 235.00933596318484, 151.1333145487003]]}, {'area': 74327, 'bbox': [130, 371, 233, 319], 'category_id': 9, 'id': 5462, 'pair_id': 823, 'image_id': 3878, 'iscrowd': 0, 'style': 8, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 389.0, 2.0, 201.0, 401.0, 1.0, 263.0, 404.0, 1.0, 165.0, 499.0, 2.0, 190.0, 591.0, 2.0, 272.0, 636.0, 2.0, 358.0, 670.0, 2.0, 325.0, 514.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[151.83262890955086, 389.4188503803873, 172.09890109890253, 401.10524091293314, 200.79712595097718, 401.253169907016, 225.62967032967032, 402.854691462382, 247.52316145393345, 401.3754015215534, 263.2036348267165, 404.48191039729346, 276.93795435333567, 433.56897717666624, 291.5829247675387, 452.65181741335505, 306.8196111580732, 475.8766694843639, 320.44412510566326, 500.2672020287382, 329.6157227388005, 513.1370245139469, 334.64530853761767, 522.6044801352499, 335.82874049028055, 534.2908706677957, 335.46289095519745, 543.1231614539245, 340.3445477599318, 558.0639898562932, 343.4510566356718, 578.9219780219763, 346.8534234995776, 605.5491969568909, 354.15950972104685, 639.9953508030401, 357.70980557903545, 663.0722738799661, 359.7808114961955, 670.1728655959433, 355.19501267962687, 678.1610312764177, 349.7216398985611, 681.7113271344064, 342.9169061707496, 679.3444632290806, 338.92282333051236, 673.1314454776006, 331.27218934911684, 674.9012679628056, 324.17159763313964, 673.2740490278941, 319.7337278106539, 661.2918005071825, 318.69822485207385, 649.1616229923881, 314.5562130177538, 634.516652578185, 307.5220625528345, 617.0752324598457, 299.82975486052584, 616.3355874894314, 290.36229923922286, 620.3296703296686, 280.74691462383703, 630.9805579036345, 272.6108199492798, 640.5959425190202, 264.4747252747226, 649.0278951817432, 253.83981403212442, 648.684192730346, 244.66821639898717, 643.5066779374459, 235.79247675401564, 639.6605240912916, 229.53693998309336, 621.1357565511408, 218.8860524091275, 588.7393068469947, 206.36880811496465, 598.2360101437025, 195.56999154691596, 598.9756551141169, 188.46939983093873, 591.431276415891, 181.9879966187681, 564.7739644970425, 173.85190194421088, 542.4366863905307, 169.48402366864252, 529.1443786982304, 160.75621301775385, 487.72426035502986, 154.24733727810806, 465.2390532544353, 151.14082840236802, 443.6414201183379, 144.67802197802393, 412.19103972949887]]}, {'area': 52074, 'bbox': [91, 29, 263, 198], 'category_id': 9, 'id': 4703, 'pair_id': 714, 'image_id': 3352, 'iscrowd': 0, 'style': 2, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 157.0, 31.0, 1.0, 228.0, 45.0, 1.0, 302.0, 33.0, 1.0, 123.0, 111.0, 2.0, 96.0, 203.0, 2.0, 241.0, 221.0, 2.0, 352.0, 205.0, 2.0, 329.0, 125.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[156.60540927216823, 31.735591001796195, 191.3027397260274, 41.03150684931507, 226.9879120879121, 44.45714285714286, 270.7013698630137, 40.49863013698631, 302.05716416548546, 32.822793826670235, 312.4176006818677, 72.94424827250536, 319.89682505860014, 93.99687985145583, 329.5921159173273, 124.19078566863479, 339.1840187513315, 153.88316641806878, 353.0344342637989, 204.85269550394887, 341.954101853825, 205.40671212444755, 331.98180268484845, 213.99396974217737, 316.95544732276005, 217.92225198624212, 306.7061398435342, 217.3682353657434, 288.9776079875759, 220.41532677848625, 269.5870262701215, 222.90840157073038, 242.60300143070478, 224.60440473653824, 245.37308453319827, 220.44928008279803, 230.1376274694841, 222.1113299442941, 210.7408663358824, 224.3513165504859, 182.7800036528541, 217.70311710450156, 182.7800036528541, 217.70311710450156, 97.46373626373627, 203.04945054945057, 109.79562265988966, 153.58841739976975, 121.87751057806436, 111.6011932665678, 134.02806916075644, 82.3378466408924, 149.54053453471994, 56.85308209795235]]}]}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1702, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1258, in load_image_gt\n","    class_ids = class_ids[_idx]\n","IndexError: boolean index did not match indexed array along dimension 0; dimension is 3 but corresponding boolean dimension is 2\n","ERROR:root:Error processing image {'id': 3352, 'source': 'deepfashion2', 'path': '/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/validation/image/003352.jpg', 'width': 468, 'height': 389, 'annotations': [{'area': 162526, 'bbox': [85, 89, 329, 494], 'category_id': 1, 'id': 5461, 'pair_id': 823, 'image_id': 3877, 'iscrowd': 0, 'style': 7, 'num_keypoints': 25, 'keypoints': [276.0, 260.0, 1.0, 251.0, 200.0, 1.0, 217.0, 251.0, 2.0, 210.0, 294.0, 2.0, 278.0, 308.0, 2.0, 350.0, 279.0, 2.0, 235.0, 152.0, 1.0, 209.0, 125.0, 2.0, 191.0, 97.0, 2.0, 144.0, 159.0, 2.0, 169.0, 185.0, 2.0, 180.0, 211.0, 2.0, 161.0, 240.0, 2.0, 126.0, 298.0, 2.0, 97.0, 355.0, 2.0, 100.0, 506.0, 2.0, 242.0, 557.0, 2.0, 267.0, 484.0, 2.0, 304.0, 424.0, 2.0, 315.0, 407.0, 2.0, 319.0, 441.0, 2.0, 316.0, 477.0, 2.0, 404.0, 466.0, 2.0, 401.0, 387.0, 2.0, 380.0, 316.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[250.78842866535504, 200.31148680379744, 230.0813186813187, 224.00879120879122, 217.26153846153846, 244.25054945054944, 215.23736263736265, 261.7934065934066, 209.83956043956044, 289.45714285714286, 209.16483516483515, 301.6021978021978, 219.28571428571428, 309.6989010989011, 253.6967032967033, 315.0967032967033, 270.5648351648352, 307.6747252747253, 305.6505494505495, 294.1802197802198, 327.91648351648354, 285.40879120879123, 343.4351648351648, 279.33626373626373, 349.5076923076923, 277.9868131868132, 350.1824175824176, 268.5406593406593, 345.4593406593407, 258.4197802197802, 336.6879120879121, 248.2989010989011, 332.63956043956046, 239.52747252747253, 340.73626373626377, 240.20219780219782, 353.55604395604394, 255.04615384615386, 354.9054945054945, 265.167032967033, 352.8813186813187, 279.33626373626373, 354.1642904104438, 283.93188691650266, 358.63503334272536, 290.5065088757402, 359.42398797783386, 294.4512820512828, 367.83950408565795, 298.1330703484558, 369.417413355875, 308.3894806048665, 377.3069597069601, 311.0193293885615, 381.25173288250267, 315.75305719921255, 383.09262703108914, 329.42827087442674, 390.45620362543525, 339.68468113083736, 393.6120221658693, 347.5742274819225, 397.81978021978136, 351.519000657465, 398.5474030243256, 361.5623931623929, 400.91426692965115, 380.4973044049971, 402.4921761998682, 393.6465483234723, 402.4921761998682, 400.4841551610794, 406.96291913214975, 409.162656147273, 405.3850098619327, 414.68533859303255, 401.1772518080207, 418.63011176857515, 403.2811308349767, 434.93517422748437, 402.7551610782377, 449.399342537807, 405.64799474030224, 468.07126890204177, 399.33635765943416, 458.34082840237016, 388.0280078895455, 451.50322156476307, 377.7715976331349, 448.347403024329, 357.2587771203136, 446.5065088757425, 342.5316239316214, 447.55844838922053, 325.43760683760365, 452.5551610782411, 319.9149243918441, 460.4447074293262, 316.49612097304055, 468.07126890204177, 317.76365173288195, 480.7577345731194, 309.34813562505786, 471.0272940734478, 314.6078331924479, 460.7708838170372, 314.87081807081745, 444.20283647975845, 316.18574246266496, 437.36522964215135, 312.76693904386144, 433.15747158823933, 313.8188785573394, 429.4756832910663, 315.39678782755647, 427.63478914247975, 313.8188785573394, 417.37837888606913, 312.5039541654919, 419.21927303465566, 310.6630600169054, 422.6380764534592, 303.2994834225593, 423.4270310885677, 301.4585892739728, 431.05359256128327, 297.77680097679973, 438.1541842772599, 289.0982999906061, 437.89119939889036, 285.6794965718026, 446.043730628345, 283.83860242321606, 456.3001408847556, 275.4230863153919, 457.08909551986414, 269.9004038696323, 467.60849065464424, 269.63741899126285, 488.384296045835, 271.2153282614799, 498.1147365455067, 260.69593312669974, 506.79323753170024, 253.0910303371841, 518.3058138442748, 251.25013618859757, 525.9323753169904, 249.14625716164153, 531.7180426411195, 248.88327228327202, 543.8153470461167, 242.57163520240394, 558.2795153564393, 231.2632854325153, 569.3248802479585, 209.83956043956044, 574.8659340659341, 187.32129238283102, 572.3954916877994, 154.1851977082736, 555.8274443505208, 123.9419366957807, 531.369850662157, 110.94730910115635, 521.4168122475834, 95.43120127735565, 494.59235465389406, 90.6974734667046, 480.39117122194085, 89.38254907485707, 453.56671362825153, 98.06105006105068, 430.1610594533657, 104.37268714191876, 388.6094486709842, 107.2655208039833, 373.88229548229197, 101.18491593876232, 367.68009768009756, 95.92521837137225, 360.31652108575145, 96.45118812811126, 352.4269747346663, 117.22699351930203, 316.9240161547834, 124.06460035690912, 304.8267117497862, 125.90549450549564, 294.8332863717451, 136.6878745186453, 271.6906170752288, 158.74372123602885, 238.62171503710016, 170.0520710059175, 225.7354559969945, 176.8896778435246, 216.53098525406187, 179.2565417488501, 210.2193481731938, 173.20788954635154, 193.12533107917608, 166.37028270874444, 182.34295106602644, 158.74372123602885, 173.1384803230938, 152.43208415516077, 163.9340095801612, 143.22761341222815, 158.41132713440163, 147.1723865877707, 143.15820418897044, 164.26640368178843, 120.10109890109891, 179.2565417488501, 104.8479759556677, 189.77593688363027, 95.64350521273509, 196.35055884286783, 103.27006668545069, 203.71413543721394, 112.47453742838331, 210.02577251808202, 121.41602329294642, 211.86666666666855, 127.2016906170755, 221.8600920447097, 133.2503428195741, 235.00933596318484, 151.1333145487003]]}, {'area': 74327, 'bbox': [130, 371, 233, 319], 'category_id': 9, 'id': 5462, 'pair_id': 823, 'image_id': 3878, 'iscrowd': 0, 'style': 8, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 389.0, 2.0, 201.0, 401.0, 1.0, 263.0, 404.0, 1.0, 165.0, 499.0, 2.0, 190.0, 591.0, 2.0, 272.0, 636.0, 2.0, 358.0, 670.0, 2.0, 325.0, 514.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[151.83262890955086, 389.4188503803873, 172.09890109890253, 401.10524091293314, 200.79712595097718, 401.253169907016, 225.62967032967032, 402.854691462382, 247.52316145393345, 401.3754015215534, 263.2036348267165, 404.48191039729346, 276.93795435333567, 433.56897717666624, 291.5829247675387, 452.65181741335505, 306.8196111580732, 475.8766694843639, 320.44412510566326, 500.2672020287382, 329.6157227388005, 513.1370245139469, 334.64530853761767, 522.6044801352499, 335.82874049028055, 534.2908706677957, 335.46289095519745, 543.1231614539245, 340.3445477599318, 558.0639898562932, 343.4510566356718, 578.9219780219763, 346.8534234995776, 605.5491969568909, 354.15950972104685, 639.9953508030401, 357.70980557903545, 663.0722738799661, 359.7808114961955, 670.1728655959433, 355.19501267962687, 678.1610312764177, 349.7216398985611, 681.7113271344064, 342.9169061707496, 679.3444632290806, 338.92282333051236, 673.1314454776006, 331.27218934911684, 674.9012679628056, 324.17159763313964, 673.2740490278941, 319.7337278106539, 661.2918005071825, 318.69822485207385, 649.1616229923881, 314.5562130177538, 634.516652578185, 307.5220625528345, 617.0752324598457, 299.82975486052584, 616.3355874894314, 290.36229923922286, 620.3296703296686, 280.74691462383703, 630.9805579036345, 272.6108199492798, 640.5959425190202, 264.4747252747226, 649.0278951817432, 253.83981403212442, 648.684192730346, 244.66821639898717, 643.5066779374459, 235.79247675401564, 639.6605240912916, 229.53693998309336, 621.1357565511408, 218.8860524091275, 588.7393068469947, 206.36880811496465, 598.2360101437025, 195.56999154691596, 598.9756551141169, 188.46939983093873, 591.431276415891, 181.9879966187681, 564.7739644970425, 173.85190194421088, 542.4366863905307, 169.48402366864252, 529.1443786982304, 160.75621301775385, 487.72426035502986, 154.24733727810806, 465.2390532544353, 151.14082840236802, 443.6414201183379, 144.67802197802393, 412.19103972949887]]}, {'area': 52074, 'bbox': [91, 29, 263, 198], 'category_id': 9, 'id': 4703, 'pair_id': 714, 'image_id': 3352, 'iscrowd': 0, 'style': 2, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 157.0, 31.0, 1.0, 228.0, 45.0, 1.0, 302.0, 33.0, 1.0, 123.0, 111.0, 2.0, 96.0, 203.0, 2.0, 241.0, 221.0, 2.0, 352.0, 205.0, 2.0, 329.0, 125.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[156.60540927216823, 31.735591001796195, 191.3027397260274, 41.03150684931507, 226.9879120879121, 44.45714285714286, 270.7013698630137, 40.49863013698631, 302.05716416548546, 32.822793826670235, 312.4176006818677, 72.94424827250536, 319.89682505860014, 93.99687985145583, 329.5921159173273, 124.19078566863479, 339.1840187513315, 153.88316641806878, 353.0344342637989, 204.85269550394887, 341.954101853825, 205.40671212444755, 331.98180268484845, 213.99396974217737, 316.95544732276005, 217.92225198624212, 306.7061398435342, 217.3682353657434, 288.9776079875759, 220.41532677848625, 269.5870262701215, 222.90840157073038, 242.60300143070478, 224.60440473653824, 245.37308453319827, 220.44928008279803, 230.1376274694841, 222.1113299442941, 210.7408663358824, 224.3513165504859, 182.7800036528541, 217.70311710450156, 182.7800036528541, 217.70311710450156, 97.46373626373627, 203.04945054945057, 109.79562265988966, 153.58841739976975, 121.87751057806436, 111.6011932665678, 134.02806916075644, 82.3378466408924, 149.54053453471994, 56.85308209795235]]}]}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1702, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1258, in load_image_gt\n","    class_ids = class_ids[_idx]\n","IndexError: boolean index did not match indexed array along dimension 0; dimension is 3 but corresponding boolean dimension is 2\n","1000/1000 [==============================] - 1063s 1s/step - loss: 0.9204 - rpn_class_loss: 0.0059 - rpn_bbox_loss: 0.2895 - mrcnn_class_loss: 0.2361 - mrcnn_bbox_loss: 0.1669 - mrcnn_mask_loss: 0.2220 - val_loss: 7.5701 - val_rpn_class_loss: 0.2990 - val_rpn_bbox_loss: 4.7018 - val_mrcnn_class_loss: 0.3869 - val_mrcnn_bbox_loss: 0.6668 - val_mrcnn_mask_loss: 1.5155\n","ERROR:root:Error processing image {'id': 3352, 'source': 'deepfashion2', 'path': '/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/dataset/validation/image/003352.jpg', 'width': 468, 'height': 389, 'annotations': [{'area': 162526, 'bbox': [85, 89, 329, 494], 'category_id': 1, 'id': 5461, 'pair_id': 823, 'image_id': 3877, 'iscrowd': 0, 'style': 7, 'num_keypoints': 25, 'keypoints': [276.0, 260.0, 1.0, 251.0, 200.0, 1.0, 217.0, 251.0, 2.0, 210.0, 294.0, 2.0, 278.0, 308.0, 2.0, 350.0, 279.0, 2.0, 235.0, 152.0, 1.0, 209.0, 125.0, 2.0, 191.0, 97.0, 2.0, 144.0, 159.0, 2.0, 169.0, 185.0, 2.0, 180.0, 211.0, 2.0, 161.0, 240.0, 2.0, 126.0, 298.0, 2.0, 97.0, 355.0, 2.0, 100.0, 506.0, 2.0, 242.0, 557.0, 2.0, 267.0, 484.0, 2.0, 304.0, 424.0, 2.0, 315.0, 407.0, 2.0, 319.0, 441.0, 2.0, 316.0, 477.0, 2.0, 404.0, 466.0, 2.0, 401.0, 387.0, 2.0, 380.0, 316.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[250.78842866535504, 200.31148680379744, 230.0813186813187, 224.00879120879122, 217.26153846153846, 244.25054945054944, 215.23736263736265, 261.7934065934066, 209.83956043956044, 289.45714285714286, 209.16483516483515, 301.6021978021978, 219.28571428571428, 309.6989010989011, 253.6967032967033, 315.0967032967033, 270.5648351648352, 307.6747252747253, 305.6505494505495, 294.1802197802198, 327.91648351648354, 285.40879120879123, 343.4351648351648, 279.33626373626373, 349.5076923076923, 277.9868131868132, 350.1824175824176, 268.5406593406593, 345.4593406593407, 258.4197802197802, 336.6879120879121, 248.2989010989011, 332.63956043956046, 239.52747252747253, 340.73626373626377, 240.20219780219782, 353.55604395604394, 255.04615384615386, 354.9054945054945, 265.167032967033, 352.8813186813187, 279.33626373626373, 354.1642904104438, 283.93188691650266, 358.63503334272536, 290.5065088757402, 359.42398797783386, 294.4512820512828, 367.83950408565795, 298.1330703484558, 369.417413355875, 308.3894806048665, 377.3069597069601, 311.0193293885615, 381.25173288250267, 315.75305719921255, 383.09262703108914, 329.42827087442674, 390.45620362543525, 339.68468113083736, 393.6120221658693, 347.5742274819225, 397.81978021978136, 351.519000657465, 398.5474030243256, 361.5623931623929, 400.91426692965115, 380.4973044049971, 402.4921761998682, 393.6465483234723, 402.4921761998682, 400.4841551610794, 406.96291913214975, 409.162656147273, 405.3850098619327, 414.68533859303255, 401.1772518080207, 418.63011176857515, 403.2811308349767, 434.93517422748437, 402.7551610782377, 449.399342537807, 405.64799474030224, 468.07126890204177, 399.33635765943416, 458.34082840237016, 388.0280078895455, 451.50322156476307, 377.7715976331349, 448.347403024329, 357.2587771203136, 446.5065088757425, 342.5316239316214, 447.55844838922053, 325.43760683760365, 452.5551610782411, 319.9149243918441, 460.4447074293262, 316.49612097304055, 468.07126890204177, 317.76365173288195, 480.7577345731194, 309.34813562505786, 471.0272940734478, 314.6078331924479, 460.7708838170372, 314.87081807081745, 444.20283647975845, 316.18574246266496, 437.36522964215135, 312.76693904386144, 433.15747158823933, 313.8188785573394, 429.4756832910663, 315.39678782755647, 427.63478914247975, 313.8188785573394, 417.37837888606913, 312.5039541654919, 419.21927303465566, 310.6630600169054, 422.6380764534592, 303.2994834225593, 423.4270310885677, 301.4585892739728, 431.05359256128327, 297.77680097679973, 438.1541842772599, 289.0982999906061, 437.89119939889036, 285.6794965718026, 446.043730628345, 283.83860242321606, 456.3001408847556, 275.4230863153919, 457.08909551986414, 269.9004038696323, 467.60849065464424, 269.63741899126285, 488.384296045835, 271.2153282614799, 498.1147365455067, 260.69593312669974, 506.79323753170024, 253.0910303371841, 518.3058138442748, 251.25013618859757, 525.9323753169904, 249.14625716164153, 531.7180426411195, 248.88327228327202, 543.8153470461167, 242.57163520240394, 558.2795153564393, 231.2632854325153, 569.3248802479585, 209.83956043956044, 574.8659340659341, 187.32129238283102, 572.3954916877994, 154.1851977082736, 555.8274443505208, 123.9419366957807, 531.369850662157, 110.94730910115635, 521.4168122475834, 95.43120127735565, 494.59235465389406, 90.6974734667046, 480.39117122194085, 89.38254907485707, 453.56671362825153, 98.06105006105068, 430.1610594533657, 104.37268714191876, 388.6094486709842, 107.2655208039833, 373.88229548229197, 101.18491593876232, 367.68009768009756, 95.92521837137225, 360.31652108575145, 96.45118812811126, 352.4269747346663, 117.22699351930203, 316.9240161547834, 124.06460035690912, 304.8267117497862, 125.90549450549564, 294.8332863717451, 136.6878745186453, 271.6906170752288, 158.74372123602885, 238.62171503710016, 170.0520710059175, 225.7354559969945, 176.8896778435246, 216.53098525406187, 179.2565417488501, 210.2193481731938, 173.20788954635154, 193.12533107917608, 166.37028270874444, 182.34295106602644, 158.74372123602885, 173.1384803230938, 152.43208415516077, 163.9340095801612, 143.22761341222815, 158.41132713440163, 147.1723865877707, 143.15820418897044, 164.26640368178843, 120.10109890109891, 179.2565417488501, 104.8479759556677, 189.77593688363027, 95.64350521273509, 196.35055884286783, 103.27006668545069, 203.71413543721394, 112.47453742838331, 210.02577251808202, 121.41602329294642, 211.86666666666855, 127.2016906170755, 221.8600920447097, 133.2503428195741, 235.00933596318484, 151.1333145487003]]}, {'area': 74327, 'bbox': [130, 371, 233, 319], 'category_id': 9, 'id': 5462, 'pair_id': 823, 'image_id': 3878, 'iscrowd': 0, 'style': 8, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 152.0, 389.0, 2.0, 201.0, 401.0, 1.0, 263.0, 404.0, 1.0, 165.0, 499.0, 2.0, 190.0, 591.0, 2.0, 272.0, 636.0, 2.0, 358.0, 670.0, 2.0, 325.0, 514.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[151.83262890955086, 389.4188503803873, 172.09890109890253, 401.10524091293314, 200.79712595097718, 401.253169907016, 225.62967032967032, 402.854691462382, 247.52316145393345, 401.3754015215534, 263.2036348267165, 404.48191039729346, 276.93795435333567, 433.56897717666624, 291.5829247675387, 452.65181741335505, 306.8196111580732, 475.8766694843639, 320.44412510566326, 500.2672020287382, 329.6157227388005, 513.1370245139469, 334.64530853761767, 522.6044801352499, 335.82874049028055, 534.2908706677957, 335.46289095519745, 543.1231614539245, 340.3445477599318, 558.0639898562932, 343.4510566356718, 578.9219780219763, 346.8534234995776, 605.5491969568909, 354.15950972104685, 639.9953508030401, 357.70980557903545, 663.0722738799661, 359.7808114961955, 670.1728655959433, 355.19501267962687, 678.1610312764177, 349.7216398985611, 681.7113271344064, 342.9169061707496, 679.3444632290806, 338.92282333051236, 673.1314454776006, 331.27218934911684, 674.9012679628056, 324.17159763313964, 673.2740490278941, 319.7337278106539, 661.2918005071825, 318.69822485207385, 649.1616229923881, 314.5562130177538, 634.516652578185, 307.5220625528345, 617.0752324598457, 299.82975486052584, 616.3355874894314, 290.36229923922286, 620.3296703296686, 280.74691462383703, 630.9805579036345, 272.6108199492798, 640.5959425190202, 264.4747252747226, 649.0278951817432, 253.83981403212442, 648.684192730346, 244.66821639898717, 643.5066779374459, 235.79247675401564, 639.6605240912916, 229.53693998309336, 621.1357565511408, 218.8860524091275, 588.7393068469947, 206.36880811496465, 598.2360101437025, 195.56999154691596, 598.9756551141169, 188.46939983093873, 591.431276415891, 181.9879966187681, 564.7739644970425, 173.85190194421088, 542.4366863905307, 169.48402366864252, 529.1443786982304, 160.75621301775385, 487.72426035502986, 154.24733727810806, 465.2390532544353, 151.14082840236802, 443.6414201183379, 144.67802197802393, 412.19103972949887]]}, {'area': 52074, 'bbox': [91, 29, 263, 198], 'category_id': 9, 'id': 4703, 'pair_id': 714, 'image_id': 3352, 'iscrowd': 0, 'style': 2, 'num_keypoints': 8, 'keypoints': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 157.0, 31.0, 1.0, 228.0, 45.0, 1.0, 302.0, 33.0, 1.0, 123.0, 111.0, 2.0, 96.0, 203.0, 2.0, 241.0, 221.0, 2.0, 352.0, 205.0, 2.0, 329.0, 125.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'segmentation': [[156.60540927216823, 31.735591001796195, 191.3027397260274, 41.03150684931507, 226.9879120879121, 44.45714285714286, 270.7013698630137, 40.49863013698631, 302.05716416548546, 32.822793826670235, 312.4176006818677, 72.94424827250536, 319.89682505860014, 93.99687985145583, 329.5921159173273, 124.19078566863479, 339.1840187513315, 153.88316641806878, 353.0344342637989, 204.85269550394887, 341.954101853825, 205.40671212444755, 331.98180268484845, 213.99396974217737, 316.95544732276005, 217.92225198624212, 306.7061398435342, 217.3682353657434, 288.9776079875759, 220.41532677848625, 269.5870262701215, 222.90840157073038, 242.60300143070478, 224.60440473653824, 245.37308453319827, 220.44928008279803, 230.1376274694841, 222.1113299442941, 210.7408663358824, 224.3513165504859, 182.7800036528541, 217.70311710450156, 182.7800036528541, 217.70311710450156, 97.46373626373627, 203.04945054945057, 109.79562265988966, 153.58841739976975, 121.87751057806436, 111.6011932665678, 134.02806916075644, 82.3378466408924, 149.54053453471994, 56.85308209795235]]}]}\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1702, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1258, in load_image_gt\n","    class_ids = class_ids[_idx]\n","IndexError: boolean index did not match indexed array along dimension 0; dimension is 3 but corresponding boolean dimension is 2\n","Epoch 5/30\n"," 129/1000 [==>...........................] - ETA: 14:59 - loss: 0.9590 - rpn_class_loss: 0.0067 - rpn_bbox_loss: 0.3129 - mrcnn_class_loss: 0.2492 - mrcnn_bbox_loss: 0.1632 - mrcnn_mask_loss: 0.2270Process ForkPoolWorker-3:\n","Process ForkPoolWorker-5:\n","Process ForkPoolWorker-4:\n","Process ForkPoolWorker-8:\n","Process ForkPoolWorker-2:\n","Process ForkPoolWorker-7:\n","Process ForkPoolWorker-6:\n","Process ForkPoolWorker-1:\n","Traceback (most recent call last):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","Traceback (most recent call last):\n","KeyboardInterrupt\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n","    with self._rlock:\n","  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n","    return self._semlock.__enter__()\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n","    task = get()\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n","    res = self._reader.recv_bytes()\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n","    buf = self._recv_bytes(maxlength)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n","    buf = self._recv(4)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n","    chunk = read(handle, remaining)\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n","    self.run()\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n","    result = (True, func(*args, **kwds))\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/data_utils.py\", line 626, in next_sample\n","    return six.next(_SHARED_SEQUENCES[uid])\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1702, in data_generator\n","    use_mini_mask=config.USE_MINI_MASK)\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 1220, in load_image_gt\n","    mask = utils.resize_mask(mask, scale, padding, crop)\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/utils.py\", line 508, in resize_mask\n","    mask = scipy.ndimage.zoom(mask, zoom=[scale, scale, 1], order=0)\n","  File \"/usr/local/lib/python3.7/dist-packages/scipy/ndimage/interpolation.py\", line 615, in zoom\n","    _nd_image.zoom_shift(filtered, zoom, None, output, order, mode, cval)\n","KeyboardInterrupt\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n","    run_metadata_ptr)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"main.py\", line 304, in <module>\n","    # Train or evaluate\n","  File \"main.py\", line 213, in train\n","    learning_rate=config.LEARNING_RATE,\n","  File \"/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/lib/model.py\", line 2370, in train\n","    use_multiprocessing=True,\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n","    return func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1418, in fit_generator\n","    initial_epoch=initial_epoch)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator.py\", line 217, in fit_generator\n","    class_weight=class_weight)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1217, in train_on_batch\n","    outputs = self.train_function(ins)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n","    return self._call(inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n","    fetched = self._callable_fn(*array_vals)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n","    run_metadata_ptr)\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ey8R98AvAXwE","executionInfo":{"status":"ok","timestamp":1626810616017,"user_tz":-540,"elapsed":16000,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"292f8204-aebe-4b28-d207-bf87b7b637be"},"source":["%cd /content/drive/MyDrive/Segmentation/Deepfashion2_Training/source\n","!python deepfashion_images.py --i /content/drive/MyDrive/Segmentation/Deepfashion2_Training/2.jpg --o /content/drive/MyDrive/Segmentation/Deepfashion2_Training/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source\n","Using TensorFlow backend.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:342: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:400: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:424: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:721: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:723: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:773: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-07-20 19:50:07.933548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-20 19:50:07.959320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:07.959984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n","pciBusID: 0000:00:04.0\n","2021-07-20 19:50:07.960315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 19:50:07.962150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 19:50:07.964545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 19:50:07.964900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 19:50:07.966815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 19:50:07.968213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 19:50:07.972378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 19:50:07.972523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:07.973161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:07.973682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 19:50:07.974085: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2021-07-20 19:50:07.978897: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz\n","2021-07-20 19:50:07.979184: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d3295c6d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 19:50:07.979211: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-20 19:50:08.065013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:08.065857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d3295c6f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 19:50:08.065890: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2021-07-20 19:50:08.066074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:08.066618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n","pciBusID: 0000:00:04.0\n","2021-07-20 19:50:08.066686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 19:50:08.066704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 19:50:08.066721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 19:50:08.066735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 19:50:08.066748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 19:50:08.066764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 19:50:08.066781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 19:50:08.066838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:08.067479: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:08.068038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 19:50:08.068111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 19:50:08.069442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 19:50:08.069468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 19:50:08.069475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 19:50:08.069581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:08.070227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 19:50:08.070795: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-20 19:50:08.070830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","2021-07-20 19:50:12.391766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 19:50:12.585770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","no of potholes in frame : 1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pB4vBdhod8il","executionInfo":{"status":"ok","timestamp":1626812429091,"user_tz":-540,"elapsed":821884,"user":{"displayName":"성균관대박길한","photoUrl":"","userId":"04206737380394195734"}},"outputId":"ed0696e3-e181-4492-97f7-61e6f1fa59fb"},"source":["%cd /content/drive/MyDrive/Segmentation/Deepfashion2_Training/source\n","!python deepfashion_videos.py --i /content/drive/MyDrive/Segmentation/Deepfashion2_Training/123.mp4"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source\n","Using TensorFlow backend.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:342: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:400: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:424: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n","Instructions for updating:\n","box_ind is deprecated, use box_indices instead\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:721: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:723: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/Segmentation/Deepfashion2_Training/Deepfashion2_Training/source/mrcnn/model.py:773: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","2021-07-20 20:06:55.141252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-07-20 20:06:55.169408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.170083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n","pciBusID: 0000:00:04.0\n","2021-07-20 20:06:55.170434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 20:06:55.172276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 20:06:55.174232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 20:06:55.174616: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 20:06:55.176461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 20:06:55.177676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 20:06:55.181767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 20:06:55.181900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.182577: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.183208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 20:06:55.183592: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2021-07-20 20:06:55.189001: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000175000 Hz\n","2021-07-20 20:06:55.189301: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562259248d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 20:06:55.189336: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-07-20 20:06:55.275498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.276317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562259248f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-07-20 20:06:55.276353: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n","2021-07-20 20:06:55.276541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.277082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n","name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n","pciBusID: 0000:00:04.0\n","2021-07-20 20:06:55.277157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 20:06:55.277199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 20:06:55.277213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2021-07-20 20:06:55.277227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2021-07-20 20:06:55.277241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2021-07-20 20:06:55.277254: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2021-07-20 20:06:55.277268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-07-20 20:06:55.277330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.277869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.278419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n","2021-07-20 20:06:55.278486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2021-07-20 20:06:55.279743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-07-20 20:06:55.279766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n","2021-07-20 20:06:55.279773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n","2021-07-20 20:06:55.279895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.280596: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-07-20 20:06:55.281216: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-07-20 20:06:55.281254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","2021-07-20 20:06:59.718467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2021-07-20 20:06:59.913149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 3\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 2\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 2\n","no of potholes in frame : 2\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 2\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 2\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 1\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 0\n","NO INSTANCES TO DISPLAY\n","no of potholes in frame : 2\n","Traceback (most recent call last):\n","  File \"deepfashion_videos.py\", line 97, in <module>\n","KeyboardInterrupt\n"],"name":"stdout"}]}]}